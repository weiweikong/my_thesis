\chapter{基于传统视觉算法的无人机目标跟踪方法研究}


\section{引言}
针对目标检测问题，很多学者提出了不同的解决方法，但目标实时监测问题中的所涉及的目标尺度变化、被遮挡和实时性等问题仍然没有得到有效解决。本章针对无人机自主降落过程中的目标跟踪问题进行进一步分析，并提出了满足实时性需求的目标跟踪算法。

\section{目标跟踪问题的概述}

 
\section{形态学滤波方法进行图像预处理}

形态学滤波（Morphological Filtering）方法是一组非线性图像运算算子。该系列算子主要包括腐蚀（Erode）、膨胀（Dilate）、开运算（Opening）和闭运算（Closing）四种基本运算。在此四种运算的基础之上，一般还可以拓展出边缘提取、凸包运算、连通区域标记等复杂运算。一般来说，由于上述算子主要通过像素之间位置，形态学处理的对象为二值图像。

在有人机的感知规避领域，机载雷达是应用最为广泛的周边环境的感知器。除此之外，安装在机身各个位置的摄像头也是感知飞行器周边环境的重要传感器。一般而言，这些摄像头主要用于在空中识别周边的其他飞行器。由于民航飞行器的空间间隔一般较大，飞行器的成像尺寸一般较小，传统的预处理方法容易将这类小型目标当做噪声忽略。2011年，卡内基梅隆大学的三位学者使用形态学滤波方法对微小无人机检测的图像进行预处理\cite{dey2011cascaded}，这篇文章图像预处理和图像检测的研究背景与本文的背景类似。
\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/chp03/01_small_uav_light_black.pdf}
	\caption{小型无人机$400\ m$在可见光相机成像效果}
	\label{fig:01_small_uav_light_black}
\end{figure}

针对本文涉及到的无人机目标识别问题，形态学滤波对图像预处理仍然是一个较为理想的方法。无人机距离摄像机较远的位置，由于机翼颜色和光照的影响，无人机的成像一般为一个亮点或一个暗点。对于试验中使用的白色无人机而言，在一次降落过程中，该无人机在距离摄像机$400\ m$左右的距离时，其成像效果如图\ref{fig:01_small_uav_light_black}所示。图中左上侧的矩形框是无人机目标放大后的结果。通过成像结果可以看到，左侧图像为无人机在转弯时，由于机翼为白色且面积较大，因此成像为一个白色为主的亮斑；右侧图像是无人机转弯完成后，无人机侧面虽然仍为白色，但由于反光面积相对较小，所以在相机中的成像为黑色为主的亮斑。


对于试验中使用的中等型号的无人机而言，其在距离摄像机$800\ m$左右的距离时，其成像效果如图\ref{fig:02_big_uav_light_black}所示。通过比较两种型号无人机的成像特性，本文设计将开运算与闭运算处理结果相减作为预处理的结果，主要针对小型无人机出现的白色和黑色亮斑变化情况进行处理。

\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/chp03/02_big_uav_light_black.pdf}
	\caption{中型无人机$800\ m$在可见光相机成像效果}
	\label{fig:02_big_uav_light_black}
\end{figure}

开运算的特点是先进行腐蚀运算，再进行膨胀运算，能够消除细小物体，突出物体边缘，即亮出的区域增大。闭运算的特点是先进行膨胀运算，再进行腐蚀运算，能够消除细小空洞，使得临近的物体相互连通，即暗处的区域增大。为了利用开运算和闭运算结果的优点，该滤波方法的基本框架如图\ref{fig:04_morphogolical_method}所示。在Ubuntu环境下使用Python实现上述预处理算法，开运算和闭运算分别对每一帧图像（$640 \times 480$）进行处理时间为$0.009\ s$至$0.013\ s$，整体时间消耗约为$0.016\ s$。

\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/chp03/04_morphogolical_method.pdf}
	\caption{形态学滤波预处理框架}
	\label{fig:04_morphogolical_method}
\end{figure}

将该算法运用到图\ref{fig:01_small_uav_light_black}中所示的图像，预处理之后的结果如图\ref{fig:03_small_uav_with_morphological}所示。结果表明，闭运算的结果减去开运算的结果能够将暗处和亮出的区域均进行筛选和保留，进一步突出小型无人机在远端时的图像特征，为后续的目标跟踪问题打下良好基础。

\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/chp03/03_small_uav_with_morphological.pdf}
	\caption{小型无人机在两种状态下使用形态学滤波处理之后的结果}
	\label{fig:03_small_uav_with_morphological}
\end{figure}


\section{基于角点检测的目标跟踪方法研究}





\section{基于主动态轮廓线的轮廓线的目标跟踪方法研究}



\section{基于Tracking-Learning-Detection的目标跟踪方法研究}
\subsection{Tracking-Learning-Detection基本框架}
TLD(Tracking-Learning-Detection)是一种针对单一目标的长时间跟踪算法(long-term tracking)。对于一段长时间的视频，我们希望对其中某个目标进行跟踪（一个人，一辆车，或者仅仅是一块运动的区域），首先在某一帧画面规定一个矩形框，框住的区域就是我们关注的目标，那么该算法做的事就是在接下来的视频中不断跟踪这个目标，无论该物体是否暂时离开画面，或者被遮挡，或者发生形变，都不会影响继续的跟踪。该框架包含这样三个部分：
\begin{itemize}
	\item 1. 跟踪器（Tracker），通过连续帧图像来预估所追踪对象的运动，这里假设帧与帧之间目标的相对运动有限，并且追踪目标保持在图像中始终可见。追踪器可能会出现追踪失败的情形，并且在目标跳出相机视野后无法恢复追踪。
	\item 2. 检测器（Detector），将各帧图像视为独立，并对每一帧图像都进行全扫面，以找出图像中所有与目标外貌相似的候选样本。该探测器会产生两类错误：错误的正样本（False Positives）和错误的负样本（False Negatives）。
	\item 3. 学习（Learning），学习过程实时观测追踪器和探测器的执行，并预估探测器的错误，生成训练样例以使能在未来避免类似的错误。学习组件假设追踪器和探测器都有可能出现失败执行，但学习组件的引入可以使得探测器生成更多的追踪目标外观，以区别背景。
\end{itemize}
\subsection{跟踪器的设计}
\subsubsection{前向后向传播算法}

\subsection{检测器的设计}
将各帧图像视为独立，并对每一帧图像都进行全扫面，以找出图像中所有与目标外貌相似的候选样本，候选样本的生成来自学习模块。该探测器会产生两类错误：错误的正样本（false positives）和错误的负样本（false negatives）。

\subsubsection{检测区域的生成}
检首先介绍一下基本的检测区域的生成和选择，即扫描窗网格。我们通过以下参数生成所有可能比例（scales）和转移（shifts）的初始边界框：比例step=1.2，水平step=10（百分比宽度），竖直step=10（百分比高度），最小边界框大小为20像素。针对一个图像（240*320）们可以生成约50K个边界框，准确数字需要基于初始边界框的宽高比。

\subsubsection{正样本区域的放射变换}
对每个正样本区域，进行$±1\%$范围的偏移，$±1\%$范围的尺度变化，$±10\%$范围的平面内旋转，并且在每个像素上增加方差为5的高斯噪声（确切的大小是在指定的范围内随机选择的），那么每个box都进行20次这种几何变换，那么10个box将产生200个仿射变换的bounding box，作为正样本。

\subsubsection{级联分类器的设计}
是由三个串行级联的三个部分组成，即级联分类器（Cascaded Classifier）。由于需要评估的边界框数量较多，每个单独的片段分类过程需要做到十分高效。如下图所示，我们将分类设计为三个阶段：图像变化（patch variance）、总体分类（ensemble classifier）、最近邻（nearest neighbor）。每个阶段都对片段进行一定的筛选排除。
\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/161002_Thesis_Tracking_Section_04.pdf}
	\caption{集成分类器示意图}
	\label{fig:161002_Thesis_Tracking_Section_04}
\end{figure}

Patch Variance: 首先利用积分图求出当前要分类扫描窗的灰度值期望，再根据期望计算出方差，与原bounding-box的方差作对比，方差小于bounding-box方差的$50\%$的扫描窗都不会通过这个分类器。（这里的阈值是可以调整的）

集成分类器（Ensemble Classifier） 主要采用随机森林（Random Forest ）的方法，其中特征选择2bitBP和Pixel Comparisions特征。Pixel Comparisons 的实现方法如下：首先，图像与高斯核进行方差为3像素的卷积，以提高转换稳健性和图像噪声。然后，根据决策树方法进行比较。


Random Forest 方法 ：andom Forests方法主要源于BinaryDecision Trees。传统的决策树主要由一系列子二叉树组成，在每一个节点通过简单的YES/NO问题进行分类。在叶子节点，表明数据所属的类型。因此，对于一个决策树而言，一组特征数据通过不同节点的判断，最终得到一个分类结果。通过训练，我们可以根据训练数据的特征，构建一棵“完美”的决策树用于实际应用。但一般而言，单棵决策树训练速度较快，可以快速处理大量数据，但存在过拟合现象，在实际应用中误差较大。为解决单棵决策树存在的缺陷，1995年Ho以及2001年Breiman分别提出采用多个决策树并引入随机特征方法，即Random Forests。其中，通过构建相互独立的多个决策树，从而提高数据处理的多样性；通过在学习过程中引入随机性，来增强系统的鲁棒性。最后，根据少数服从多数的投票原则，判定一个数据的类别。

对样本的处理。Bootstrap Sampling 思想。通过有重复的随机抽取样本，重新组成新的样本集。原始数据集的数学表示如下：
$$\mathbf{\{Dat}{{\mathbf{a}}_{\mathbf{1}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{2}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{3}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{4}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{5}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{6}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{7}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{8}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{9}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{10}}}\mathbf{\}}$$

随机抽取之后的数据集如下：
$$\mathbf{\{Dat}{{\mathbf{a}}_{\mathbf{7}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{6}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{3}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{1}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{1}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{8}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{7}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{2}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{9}}}\mathbf{,Dat}{{\mathbf{a}}_{\mathbf{5}}}\mathbf{\}}$$

可以看到，则随机抽取之后的数据样本集中，不仅样本集的顺序发生了改变，个别样本集也出现了重复。

子特征集的提取。系统不再对全部特征进行训练，而是从中随机选出一个子集进行训练，基于这些子集得到不同类型的决策树。


Random Fern 方法：Random Fern 的思想就是用多个特征组合来表达对象。


\begin{figure}[htb]   
	\centering
	\includegraphics[width=\textwidth]{figs/161002_Thesis_Tracking_Section_05.pdf}
	\caption{集成分类器示意图}
	\label{fig:161002_Thesis_Tracking_Section_05}
\end{figure}

Random Fern 方法基于贝叶斯理论，主要是对简单贝叶斯分类器（Navie Bayes Classifiers）的改进。对于不同的特征$(f_1, f_2, ..., f_N)$而言，分类的最大化这些特征的后验概率：

$$\arg \max_{k}P(C_k|f_1, f_2, ..., f_N)$$

通过贝叶斯公式可以转换为求解最大化极大似然函数与先验概率的乘积

$$\arg \max_{k}P(f_1, f_2, ..., f_N|C_k)P(C_k)$$

这里引入各个特征相互独立的基本假设，方程可以将极大似然函数的求解进一步化简为
$$
P(f_1, f_2, ..., f_N|C_k)=\prod\limits_{i=1}^{N}P(f_i|C_k)
$$
此时，可以得到新的分类公式
$$
\arg\max_kP(C_k)\prod\limits_{i=1}^{N}P(f_i|C_k)
$$
但是在实际问题的求解过程中，每个特征的独立性假设过于严格，因此2007年的CVPR M.Oezuysal中提出Semi-Navie Bayes方法，即将特征进行分组，认为组与组之间保持严格的独立性，而组件的特征相互依赖。假设所有的特征可以分为$L$个组别，每个组别中包含$S$个特征，每个组别被称为Ferns，每一个特征组的表达为
$$
\mathbf{F}_l=\{f_{l,1}, f_{l,2},..., f_{l,S}\}
$$
为了在检测过程中计算便捷，选用二维编码的方式对图像进行描述，因此每一个特征满足$f_n\in\{{0,1}\}$。由此，可以进一步将极大似然函数重新表达
$$
P(f_1, f_2, ..., f_N|C_k)=\prod\limits_{i=1}^{L}P(\mathbf{F}_l|C_k)
$$
基于特征分组的分类公示为
$$
\arg\max_kP(C_k)\prod\limits_{i=1}^{L}P(\mathbf{F}_i|C_k)
$$
在实际训练过程中，由于训练样本数量较少，会导致分类概率为零的情况。因此，我们认为$P(\mathbf{F}|C_k)$符合Dirchlet分布，因此设定一个最小的概率输出
$$
p(\mathbf{F}=z|C_k)=\frac{\mathbb{N}(\mathbf{F}=z|C_k)+1}{\sum_{z=0}^{2^S-1}(\mathbb{N}(\mathbf{F}=z|C_k)+1)}
$$
其中，$\mathbb{N}(\mathbf{F}=z|C_k)$是计算在类别$C_k$情况下，观测到$\mathbf{F}=z$的特征个数。

\subsection{学习器的设计}
学习模块（Leaner）学习过程实时观测追踪器和探测器的执行，并预估探测器的错误，生成训练样例以使能在未来避免类似的错误。学习组件假设追踪器和探测器都有可能出现失败执行，但学习组件的引入可以使得探测器生成更多的追踪目标外观（generalizes to more object appearances），以区别背景。

PN学习即PN learning, P指代Positive Constraint,也称之为P-expert或者growing event,N指代Negative Constraint,也称之为N-expert或者pruning event。

P-expert的作用是发现目标的新的外观（形变），并以此来增加正样本的数量，从而使得检测模块更具鲁棒性；N-expert的作用是生成负的训练样本。N-expert的前提假设是，（被跟踪的）前景目标仅可能出现在视频帧中的一个位置，因此，如果前景目标的位置是确定的，那么其周围必然是负样例。

TLD模块中的PN学习作用是通过对视频序列的在线处理来逐步改善检测模块(TLD中的Detection)的性能。对视频中的每一帧而言，我们希望评估检测模块在当前帧中的误检，并以此来更新目标模型，从而使得在以后的视频帧处理过程中避免类似的错误再次发生。PN学习的关键在于两种类型的“专家(experts)”：P-experts检查那些被检测模块错误分类为正样本（前景目标）的数据；N-experts检查哪些被检测模块错误分类为负样本(背景)的数据；需要提醒的是，无论P-experts还是N-experts都会产生一定的偏差。那么，如果用这些存在偏差的数据来更新检测模块（目标模型），是否会造成检测模型的性能恶化呢？作者经过研究发现，尽管存在误差，在一定条件下，误差是允许的，并且检测模块的性能会因此得到改善。

PN学习包含四个部分：（1）一个待学习的分类器；（2）训练样本集–一些已知类别标签的样本；（3）监督学习–一种从训练样本集中训练分类器的方法；（4）P-N experts–在学习过程中用于产生正（训练）样本和负（训练）样本的表达函数；这四个部分之间的关系如下图所示：

首先根据一些已有类别标记的样本，借助监督学习方法来训练，从而得到一个初始分类器。之后，通过迭代学习，利用上一次迭代得到的分类器对所有的未赋予标签的样本数据进行分类，而P-N experts则找出那些错误分类的样本，并依此来对训练样本集做出修正，使得下一次迭代训练之后得到的分类器的性能有所改善。P-experts将那些被分类器标记为负样本，但根据结构性约束条件应该为正样本的那些样本赋予“正”的标签，并添加到训练样本集中；而N-experts则将那些被分类器标记为正样本，但根据结构性约束条件应该为负样本的那些样本赋予“负”的标签，并添加到训练样本集当中；这也就意味着，P-experts增加了分类器的鲁棒性，而N-experts则增加了分类器的判别能力。

每一个扫描窗口就表示一个图像片(image patch)，图像片的类别标签用(b)(c)中的彩色圆点来表示。检测模块对每个图像片的类别赋值过程是彼此独立的，因此，N个扫描窗口就存在个类别标签的组合。而(b)则显示了其中一种可能的类别标签形式，这种类别标签标明，待检测目标在一个视频帧中可能同时出现在好几个区域，并且，待检测目标在相邻视频帧之间的运动没有连续性（例如(b)中最前面的图像中右上角的红色圆点在后面的两个图像中均没有出现），显然，这种类别标签形式是错误的。相反，(c)所示的类别标签形式则显示，每个视频帧中，目标只可能出现在一个区域，并且，相邻视频帧之间检测到的目标区域是连续了，构成了一个目标的运动轨迹。这种性质，我们称之为“结构性”的。PN学习的关键就是找到这种结构性的数据，从而来判别检测模块所产生的错误标签。

上述例子表明：P-experts寻找视频序列中的时域上的结构性特征，并且假设目标是沿着轨迹线移动的，即，相邻帧之间的移动很小，且存在一定的相关性。P-experts记录目标在上一帧中的位置，并根据帧与帧之间的跟踪算法（这里采用的是LK光流法）来预测目标在当前帧中的位置。如果检测模块将跟踪算法预测到的目标在当前帧中的位置标记为负标签，那么P-experts就产生一个正的训练样本；N-experts寻找视频序列中的空间域上的结构性特征，并且假设目标在一个视频帧中只可能出现在一个位置。N-experts对检测模块在当前帧中的所有输出结果以及跟踪模块的输出结果进行分析，并找到具有最大可能性的那个区域。当前帧中所有目标可能出现的区域当中，如果某个区域同最大可能性区域之间没有重叠，就将其认定为负样本。另外，具有最大可能性的那个区域，被用于重新初始化跟踪模块。




 